<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Soft Machine | Zhuoyuan Mai </title> <meta name="author" content=" Zhuoyuan Mai"> <meta name="description" content="Zhuoyuan Mai's personal website. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?36622fe3ab07431bef0ae2af5aaac6da"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhuoyuanmai1.github.io/projects/softmachine/"> <script src="/assets/js/theme.js?f6c3adbe57abc76bc7ac988980b2b057"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container d-flex justify-content-between align-items-center"> <a href="/" class="navbar-brand"> <img src="/assets/img/home.webp" style="width: 24px; height: 24px;" alt="Home Icon"> </a> <div class="d-flex"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> </div> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/projects/">Works <span class="sr-only">(current)</span> </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Soft Machine</h1> <p class="post-description"></p> </header> <article> <p>As Technology develops by leaps and bounds, artificial intelligence is beginning to show the same way of thinking as a human being, with a process based on big data. I can’t help wondering if AI perceives clothing in the same way as humans do.</p> <p>The aim of this project is to create a perceptual match scoring system for clothing,which calculates from subjective perception to objective evaluation. Another point is to create a textile-specific neural networks database to streamline the pattern collection and generation process.</p> <div class="row"> <div class="col-12"> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/3_ddmO2WKLU?si=hsbRwVSwM7Uh0dgu" allowfullscreen=""></iframe> </div> </div> </div> <hr> <h3 id="gallery">Gallery</h3> <hr> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/2.webp-480.webp 480w,/assets/img/softmachine/4x/2.webp-800.webp 800w,/assets/img/softmachine/4x/2.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/2.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h3 id="research">Research</h3> <hr> <h4> <br> Inspiration </h4> <p> <br> Relying on a huge database, artificial intelligence has gradually built up the perception of fabric style. So when matching face information with clothing information on a one-to-one basis, can AI analyze the degree of matching between them, and are the results the same as human analysis? </p> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/3.webp-480.webp 480w,/assets/img/softmachine/4x/3.webp-800.webp 800w,/assets/img/softmachine/4x/3.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/3.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4> <br> <a href="https://en.wikipedia.org/wiki/Kansei_engineering" target="_blank" rel="external nofollow noopener">Kansei Engineering</a> </h4> <p> <br> Kansei engineering (emotional or affective engineering) aims at the development or improvement of products and services by translating the customer's psychological feelings and needs into the domain of product design (i.e. parameters). </p> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/4.webp-480.webp 480w,/assets/img/softmachine/4x/4.webp-800.webp 800w,/assets/img/softmachine/4x/4.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/4.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/5.webp-480.webp 480w,/assets/img/softmachine/4x/5.webp-800.webp 800w,/assets/img/softmachine/4x/5.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/5.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p> It was founded by Mitsuo Nagamachi, Professor Emeritus of Hiroshima University Kansei engineering parametrically links the customer's emotional responses (i.e. physical and psychological) to the properties and characteristics of a product or service. <br><br> In consequence, products can be designed to bring forward the intended feeling. </p> <h4> <br> <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" target="_blank" rel="external nofollow noopener">GANS</a> </h4> <p> <br> The Generative Adversarial Neural Network (GAN) architecture, introduced by Goodfellow et al., is a machine learning model that can be used to generate images of fabric with specific styles and patterns. <br><br> This architecture allows researchers in the field of textiles to use self-defined datasets to predict and generate images of various fabrics, making it a useful tool for research and development in multiple areas. <br><br> GANs can be trained on a wide range of datasets, allowing for the creation of highly realistic images that can be used for various purposes, such as design, analysis, and evaluation. </p> <div class="row justify-content-center"> <div class="col-10"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/6.webp-480.webp 480w,/assets/img/softmachine/4x/6.webp-800.webp 800w,/assets/img/softmachine/4x/6.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/6.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p> <br> The Frict GAN architecture, proposed by Cai et al., is a neural network-based approach for recognizing fabric texture images and simulating haptic signals associated with the surface of fabric materials. The neural network processes information about fabric smoothness and generates displacement data and amplitude spectra of fabric friction coefficients. These generated haptic signals can be used in haptic feedback studies to better understand the tactile properties of fabric materials.<br><br> In the context of fabric materials, haptic feedback can be used to study the way that fabrics feel to the touch and how they respond to different forces and stimuli. By simulating haptic signals with the Frict GAN architecture, researchers can gain a better understanding of the tactile properties of different fabrics and potentially use this information to design materials with desired haptic properties. </p> <div class="row justify-content-center"> <div class="col-10"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/7.webp-480.webp 480w,/assets/img/softmachine/4x/7.webp-800.webp 800w,/assets/img/softmachine/4x/7.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/7.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4> <br> Sketch </h4> <p> <br> As for the medium to realize the project, I decide to make use of multi-screens and design a viusal panel which can turn data into visual language and depict different properties on the screens. </p> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/8.webp-480.webp 480w,/assets/img/softmachine/4x/8.webp-800.webp 800w,/assets/img/softmachine/4x/8.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/8.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h3 id="physical-experiment">Physical Experiment</h3> <hr> <h4> <br> Sample Selection </h4> <p> <br> With cooperation of the FDC Fabric Centre (affiliated to BIFT), I selected 25 types of fabric as original samples.<br><br>Samples are selected according to the following seven properties: color, material, thickness, fluffiness, softness, roughness and texture. </p> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/9.webp-480.webp 480w,/assets/img/softmachine/4x/9.webp-800.webp 800w,/assets/img/softmachine/4x/9.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/9.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4> <br> Questionnaire </h4> <div class="row"> <div class="col-sm-4" style="display: flex; align-items: center;"> <div style="text-align: left;"> <p> <br> Based on the listed properties, I conducted a questionare survey entitled Are These Good Fabrics to analyze the subjective fabric style. <br><br> 20 experimenters involved, including 10 males and 10 females.<br><br> After arithmetic meaning the results, the diagram is on the right side.<br><br> The results of the collection would be used in the subsequent search for potential factors and to complete the correlation between subjective perception and objective fabric attributes. </p> </div> </div> <div class="col-sm-8"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/10.webp-480.webp 480w,/assets/img/softmachine/4x/10.webp-800.webp 800w,/assets/img/softmachine/4x/10.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/10.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/11.webp-480.webp 480w,/assets/img/softmachine/4x/11.webp-800.webp 800w,/assets/img/softmachine/4x/11.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/11.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Cross Analysis </div> <h4> <br> Physics Analysis </h4> <p> <br> Apart from subjective survey, objective measurement is also important. Seven analytical methods were applied to measure the listed properties. </p> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/12.webp-480.webp 480w,/assets/img/softmachine/4x/12.webp-800.webp 800w,/assets/img/softmachine/4x/12.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/12.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4> <br> Conclusion </h4> <p> <br> Above all the experiments, the best fit is for the subjective and objective thickness and roughness tests, indicating a strong correlation between the subjective perception of thickness and roughness and the actual nominal thickness and roughness of the fabric samples.<br><br> The subjective and objective data of the fluffiness, stiffness and texture analyses are more discrete than for the thickness and roughness experiments, indicating a discrepancy between the testing and statistical methods and the subjective style perceptions.<br><br> The correlation between the subjective factors of samples means that people's evaluation on fabric styles is the result of the interaction of different factors.<br><br> The subjective factors of the fabric samples correlate to some extent with the trend of the objective attributes with the change in sample number, especially the good fit between the subjective perception of thinness and roughness and the actual nominal thickness and roughness, indicating that the sample attributes influence people's subjective style perception of the fabric. </p> <hr> <h3 id="computational-experiment">Computational Experiment</h3> <hr> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/13.webp-480.webp 480w,/assets/img/softmachine/4x/13.webp-800.webp 800w,/assets/img/softmachine/4x/13.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/13.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h3 id="visual-development">Visual Development</h3> <hr> <div class="row"> <div class="col-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/softmachine/4x/14.webp-480.webp 480w,/assets/img/softmachine/4x/14.webp-800.webp 800w,/assets/img/softmachine/4x/14.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/softmachine/4x/14.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Zhuoyuan Mai. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?2fa796dc3761031134e3079bc048f6e1"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>